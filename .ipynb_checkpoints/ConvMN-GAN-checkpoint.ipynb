{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T13:57:41.60206Z",
     "iopub.status.busy": "2021-06-20T13:57:41.601772Z",
     "iopub.status.idle": "2021-06-20T13:57:44.193075Z",
     "shell.execute_reply": "2021-06-20T13:57:44.192254Z",
     "shell.execute_reply.started": "2021-06-20T13:57:41.601991Z"
    },
    "id": "x561-XD-JziU"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 9) # (w, h)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from random import sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T13:57:44.194804Z",
     "iopub.status.busy": "2021-06-20T13:57:44.194452Z",
     "iopub.status.idle": "2021-06-20T13:57:44.207911Z",
     "shell.execute_reply": "2021-06-20T13:57:44.207007Z",
     "shell.execute_reply.started": "2021-06-20T13:57:44.194767Z"
    },
    "id": "-x1XBc7fJ0-y",
    "outputId": "6c87eef3-aa3c-4a2b-8580-7571e901a313"
   },
   "outputs": [],
   "source": [
    "n_epochs = 2000\n",
    "batch_size = 146\n",
    "lr = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "n_cpu = 8\n",
    "latent_dim = 100\n",
    "channels = 1\n",
    "sample_interval = 400\n",
    "\n",
    "torch.manual_seed(3110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T13:57:44.211254Z",
     "iopub.status.busy": "2021-06-20T13:57:44.211008Z",
     "iopub.status.idle": "2021-06-20T13:57:46.288548Z",
     "shell.execute_reply": "2021-06-20T13:57:46.287715Z",
     "shell.execute_reply.started": "2021-06-20T13:57:44.211229Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "dir = \"Adj\"\n",
    "arrays = []\n",
    "for filename in os.listdir(dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        arrays.append(np.load(dir + \"/\"+filename))\n",
    "v = arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T13:57:46.291114Z",
     "iopub.status.busy": "2021-06-20T13:57:46.290869Z",
     "iopub.status.idle": "2021-06-20T13:57:46.300626Z",
     "shell.execute_reply": "2021-06-20T13:57:46.299793Z",
     "shell.execute_reply.started": "2021-06-20T13:57:46.291089Z"
    },
    "id": "NOsqGtPILm2Y"
   },
   "outputs": [],
   "source": [
    "img_size = v[0].shape[1]\n",
    "v_train, v_test = train_test_split(v, test_size=0.2, random_state=42)\n",
    "v = v_train\n",
    "print(len(v_train), len(v_test), len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T13:57:46.703828Z",
     "iopub.status.busy": "2021-06-20T13:57:46.703461Z",
     "iopub.status.idle": "2021-06-20T13:57:46.782669Z",
     "shell.execute_reply": "2021-06-20T13:57:46.781467Z",
     "shell.execute_reply.started": "2021-06-20T13:57:46.703788Z"
    },
    "id": "QSJXGj0YKcTo",
    "outputId": "38f83c12-a2a8-490b-f989-2f522cdc999d"
   },
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T13:57:46.785412Z",
     "iopub.status.busy": "2021-06-20T13:57:46.784693Z",
     "iopub.status.idle": "2021-06-20T13:57:46.793162Z",
     "shell.execute_reply": "2021-06-20T13:57:46.79218Z",
     "shell.execute_reply.started": "2021-06-20T13:57:46.785369Z"
    },
    "id": "f2fXUfACKgPT"
   },
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T13:57:46.7981Z",
     "iopub.status.busy": "2021-06-20T13:57:46.797233Z",
     "iopub.status.idle": "2021-06-20T13:57:46.811382Z",
     "shell.execute_reply": "2021-06-20T13:57:46.809896Z",
     "shell.execute_reply.started": "2021-06-20T13:57:46.798053Z"
    },
    "id": "WdTy-HULKuXy"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.init_size = img_size // 4\n",
    "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            #PrintLayer(), # Add Print layer for debug\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            #PrintLayer(), # Add Print layer for debug\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            #PrintLayer(), # Add Print layer for debug\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
    "            #PrintLayer(), # Add Print layer for debug\n",
    "            nn.ReLU()\n",
    "            #nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T13:57:46.817907Z",
     "iopub.status.busy": "2021-06-20T13:57:46.815641Z",
     "iopub.status.idle": "2021-06-20T13:57:46.829307Z",
     "shell.execute_reply": "2021-06-20T13:57:46.828136Z",
     "shell.execute_reply.started": "2021-06-20T13:57:46.817842Z"
    },
    "id": "H2sSAcSj7LO2"
   },
   "outputs": [],
   "source": [
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrintLayer, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Do your print / debug stuff here\n",
    "        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T13:57:46.831179Z",
     "iopub.status.busy": "2021-06-20T13:57:46.830713Z",
     "iopub.status.idle": "2021-06-20T13:57:46.8413Z",
     "shell.execute_reply": "2021-06-20T13:57:46.840246Z",
     "shell.execute_reply.started": "2021-06-20T13:57:46.831145Z"
    },
    "id": "2VrWj7X9K0jn"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = img_size // 2 ** 4\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T13:57:46.842921Z",
     "iopub.status.busy": "2021-06-20T13:57:46.842561Z",
     "iopub.status.idle": "2021-06-20T13:57:51.130454Z",
     "shell.execute_reply": "2021-06-20T13:57:51.129677Z",
     "shell.execute_reply.started": "2021-06-20T13:57:46.842884Z"
    },
    "id": "bpQCwjOwK75o",
    "outputId": "27f8a597-dbee-421b-f474-112c59523eb5"
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialization\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "\n",
    "# Initialize weights\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T13:57:51.132001Z",
     "iopub.status.busy": "2021-06-20T13:57:51.13167Z",
     "iopub.status.idle": "2021-06-20T13:57:51.138735Z",
     "shell.execute_reply": "2021-06-20T13:57:51.137703Z",
     "shell.execute_reply.started": "2021-06-20T13:57:51.131964Z"
    },
    "id": "4ZMeRf2H7RjC",
    "outputId": "7ed336fa-5df2-41d9-bf27-51c5bfc39cf6"
   },
   "outputs": [],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T13:57:51.140591Z",
     "iopub.status.busy": "2021-06-20T13:57:51.140187Z",
     "iopub.status.idle": "2021-06-20T13:57:51.150602Z",
     "shell.execute_reply": "2021-06-20T13:57:51.148637Z",
     "shell.execute_reply.started": "2021-06-20T13:57:51.140555Z"
    }
   },
   "outputs": [],
   "source": [
    "discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T13:57:51.15222Z",
     "iopub.status.busy": "2021-06-20T13:57:51.15195Z",
     "iopub.status.idle": "2021-06-20T13:57:51.193217Z",
     "shell.execute_reply": "2021-06-20T13:57:51.192393Z",
     "shell.execute_reply.started": "2021-06-20T13:57:51.152194Z"
    },
    "id": "ZXhbvT_OLAom"
   },
   "outputs": [],
   "source": [
    "class VectorialDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_data, transform=None):\n",
    "        super(VectorialDataset, self).__init__()\n",
    "        self.input_data = torch.tensor(np.expand_dims(input_data, axis = 1)).float()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input_data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sample = self.input_data[idx, :]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample \n",
    "\n",
    "\n",
    "training_set = VectorialDataset(input_data=v)\n",
    "dataloader = torch.utils.data.DataLoader(training_set, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T13:57:51.218233Z",
     "iopub.status.busy": "2021-06-20T13:57:51.217876Z",
     "iopub.status.idle": "2021-06-20T13:57:51.22467Z",
     "shell.execute_reply": "2021-06-20T13:57:51.223733Z",
     "shell.execute_reply.started": "2021-06-20T13:57:51.218196Z"
    },
    "id": "ocALOAv7LDzd"
   },
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2),weight_decay=1e-4)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr= lr, betas=( b1,  b2), weight_decay=1e-4)\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T13:57:51.226768Z",
     "iopub.status.busy": "2021-06-20T13:57:51.226217Z",
     "iopub.status.idle": "2021-06-20T14:15:10.654186Z",
     "shell.execute_reply": "2021-06-20T14:15:10.653266Z",
     "shell.execute_reply.started": "2021-06-20T13:57:51.226728Z"
    },
    "id": "Jj8E94ebLKfh",
    "outputId": "9b743ad8-a14e-41f7-addb-466a575dfaae",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fake_process = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "maxes = []\n",
    "\n",
    "real_scores = np.zeros(n_epochs)\n",
    "fake_scores = np.zeros(n_epochs)\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, imgs in enumerate(dataloader):\n",
    "\n",
    "        # labels\n",
    "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Training Gen\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Gen input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0],  latent_dim))))\n",
    "\n",
    "\n",
    "        # Generate a batch of matrices\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # G loss\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Training Discr\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        # D loss\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        #Accuracies\n",
    "        outputs = discriminator(real_imgs)\n",
    "        real_score = outputs\n",
    "        outputs = discriminator(gen_imgs.detach())\n",
    "        fake_score = outputs\n",
    "\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "\n",
    "        if epoch%100 == 0 and i == len(dataloader)-1:\n",
    "            print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "            % (epoch, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "            )\n",
    "            \n",
    "        \n",
    "        # Save Losses for plotting later and accuracies\n",
    "        G_losses.append(g_loss.item())\n",
    "        D_losses.append(d_loss.item())\n",
    "\n",
    "        real_scores[epoch] = real_scores[epoch]*(i/(i+1.)) + real_score.mean().data*(1./(i+1.))\n",
    "        fake_scores[epoch] = fake_scores[epoch]*(i/(i+1.)) + fake_score.mean().data*(1./(i+1.))\n",
    "        \n",
    "        if n_epochs%25 == 0  and i == len(dataloader)-1:               \n",
    "            np_arr = np.rint(gen_imgs[0][0].cpu().detach().numpy()).astype(int)\n",
    "            fake_process.append(np_arr)\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T14:18:38.460507Z",
     "iopub.status.busy": "2021-06-20T14:18:38.460166Z",
     "iopub.status.idle": "2021-06-20T14:18:38.814364Z",
     "shell.execute_reply": "2021-06-20T14:18:38.813413Z",
     "shell.execute_reply.started": "2021-06-20T14:18:38.460478Z"
    },
    "id": "5JlfC3CRPn60"
   },
   "outputs": [],
   "source": [
    "plt.title(\"ConvMN-GAN Training\", size = 23, fontweight=\"bold\")\n",
    "plt.plot(G_losses,label=\"Generator\")\n",
    "plt.plot(D_losses,label=\"Discriminator\")\n",
    "plt.xlabel(\"iterations\", size = 23)\n",
    "plt.ylabel(\"loss\", size = 23)\n",
    "\n",
    "plt.tick_params(labelsize=20)\n",
    "\n",
    "plt.legend(prop={'size': 18})\n",
    "plt.savefig('lossDCGAN.pdf')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T14:19:36.187697Z",
     "iopub.status.busy": "2021-06-20T14:19:36.187315Z",
     "iopub.status.idle": "2021-06-20T14:19:36.495068Z",
     "shell.execute_reply": "2021-06-20T14:19:36.494265Z",
     "shell.execute_reply.started": "2021-06-20T14:19:36.187666Z"
    },
    "id": "amZ7cHAz7QLe"
   },
   "outputs": [],
   "source": [
    "plt.title(\"ConvMN-GAN: Scores\", size = 23, fontweight=\"bold\")\n",
    "plt.plot(fake_scores, label='synthetic score')\n",
    "plt.plot(real_scores, label='real score')    \n",
    "\n",
    "plt.xlabel(\"epochs\", size = 23)\n",
    "plt.ylabel(\"score\", size = 23)\n",
    "\n",
    "plt.tick_params(labelsize=20)\n",
    "\n",
    "plt.legend(prop={'size': 18})\n",
    "plt.savefig(\"scoresDCGAN.pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
